
                                    Abstract
Vector representation of words has been learned by many methods, word2vec is one of them and used in many natural language processing and information retrieval.  Though vector representation of words has been applied for DBpedia data to predict DBpedia properties, the surprising fact is that it has not been applied for DBpedia data to aggregate semantic information stored in word embeddings. This project targets to introduce a new system called super vector, which is capable to accumulate several vectors in the analogy task to predict the relation target of DBpedia and which can incredibly increase the accuracy of the analogous characteristic of the vectors. The following four relations namely capital-country, currency-country, person-party and spouse are considered from DBpedia for this study. Although vector numbers are also used to evaluate the systemâ€™s performance, average accuracy has to be determined. The highest accuracy is obtained by capital-country relationship and the amount is around 94\%. This result shows that the method super vector is much more efficient and promising to do more research in enhancing performance.

For detailed information, please read Report_Relation_Prediction.pdf.
