
                                    Abstract
Vector representation of word has been learned by many methods, word2vec is one
of them and used in many natural language processing and information retrieval to
detect word similarity, analogical reasoning and so on. However, vector representation
of word has been applied for DBpedia data regarding the relational task, but it has
not been yet applied for DBpedia data to aggregate semantic information stored in
word embeddings. This project targets to increase the accuracy of analogical reasoning
by aggregating semantic information of DBpedia data to predict the relation targets.
Therefore, we introduced two super vectors, which are capable to accumulate several
vectors in the analogy task and which can incredibly increase the accuracy of the
analogous characteristic of the vectors. The following four relations namely capitalcountry,
currency-country, person-party and company-headquarter are considered from
DBpedia for this study to evaluate the system performance. With the increasing number
of vectors, the performance has increased for all of the above-described relations and
the highest performance was achieved by the company-headquarter relation.

For detailed information, please read Report_Relation_Prediction.pdf.
